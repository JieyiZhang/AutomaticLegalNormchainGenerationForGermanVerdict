{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.dom.minidom import parse, parseString\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normchain(doc):\n",
    "# Return all legal norms in the norm chain in node \"NORM\" in each verdict documentation\n",
    "    norm_chain = []\n",
    "    for node in doc.getElementsByTagName('NORM'):\n",
    "        for t in node.childNodes:\n",
    "            print(t.nodeValue)\n",
    "            norm_chain.append(t.nodeValue)\n",
    "    return norm_chain\n",
    "\n",
    "def preprocess_extraction(ext):\n",
    "# Clean the extracted norms and append them into a list in the one of following forms:\n",
    "#     1. Law code abbreviation\n",
    "#     2. Law code abbreviation + Article number\n",
    "#     3. Law code abbreviation + Article number + Abs. paragraph number\n",
    "# The form of the appended norm depends on the granularity of the extracted norm\n",
    "    processed=[]\n",
    "    for e in ext:\n",
    "        e = e[0]\n",
    "        if ',' in e:\n",
    "            # print(e)\n",
    "            words = e.split()\n",
    "            indices = [i-1 for i, x in enumerate(words) if x == \"Abs.\"]\n",
    "            if len(indices)==1:\n",
    "                words = re.split(' |, ', e)\n",
    "                for j in range(2,len(words)-1):\n",
    "                    l=' '.join(list( words[i] for i in [0, 1, j, -1] ))\n",
    "                    processed.append(l)\n",
    "            if len(indices)>1:\n",
    "                for i in range(len(indices)):\n",
    "                    if i!=len(indices)-1:\n",
    "                        string = ' '.join(words[indices[i]:indices[i+1]])\n",
    "                        string = string[:-1]+' '+words[-1]\n",
    "                        processed.append(string)\n",
    "                    else:\n",
    "                        processed.append(' '.join(words[indices[i]:len(words)]))\n",
    "        else:\n",
    "            processed.append(e)\n",
    "    return processed\n",
    "\n",
    "\n",
    "def get_normsAll(tree):\n",
    "# Return all norms annotated in relevant sections (except NORM and NORMENKETTE) in \n",
    "# each verdict documentation\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    sections = ['SCHLAGWORT', 'ANMERKUNG',\n",
    "                'UNTERSCHLAGWORT', 'ENTSCHEIDUNGSFORMEL',\n",
    "                'LEITSATZ', 'TATBESTAND', 'NACHGEHEND', 'GRUENDE']\n",
    "    \n",
    "    section_weights = {'SCHLAGWORT':1, 'ANMERKUNG':1,\n",
    "            'UNTERSCHLAGWORT':1, 'ENTSCHEIDUNGSFORMEL':1,\n",
    "            'LEITSATZ':2, 'TATBESTAND':1, 'NACHGEHEND':1, 'GRUENDE':1}\n",
    "    \n",
    "    # output dictionary\n",
    "    norms = {}\n",
    "    \n",
    "    # pattern for norm extraction\n",
    "    pattern = '§\\s(\\d+[a-zA-ZäüöÄÜÖß]*[\\sFall|Abs.|Satz|Nr.\\s\\d+[,\\s\\d+]*]*\\s([a-z]+ )*[A-Z][a-zA-ZäüöÄÜÖß]+)'    \n",
    "    \n",
    "    for section in sections:\n",
    "        for node in root.iter(section):\n",
    "            for i in node.iter():\n",
    "                # Match from plain text\n",
    "                if i.tag != 'VERWEIS-GS':\n",
    "                    string = i.text\n",
    "                    try:\n",
    "                        ext = re.findall(pattern, string)\n",
    "                        processed = preprocess_extraction(ext)\n",
    "                        for e in processed:\n",
    "                            book = re.findall('(\\w+)',e)[-1]\n",
    "                            art = re.findall('(\\d+)',e)[0]\n",
    "                            norm = book + ' ' + art\n",
    "                            if norm not in norms:\n",
    "                                norms[norm] = {}\n",
    "                            art_abs = re.findall('(\\d+\\w+\\sAbs.\\s\\d+)',e)\n",
    "                            if art_abs==[]:\n",
    "                                if norm in norms[norm]:\n",
    "                                    norms[norm][norm] += section_weights[section]\n",
    "                                else:\n",
    "                                    norms[norm][norm] = section_weights[section]\n",
    "                            else:\n",
    "                                for s in art_abs:\n",
    "                                    name = book + ' '  + s\n",
    "                                    if name in norms[norm]:\n",
    "                                        norms[norm][name] += section_weights[section]\n",
    "                                    else:\n",
    "                                        norms[norm][name] = section_weights[section]                                \n",
    "                    except:\n",
    "                        pass\n",
    "                else:\n",
    "                # Extract from node\n",
    "                    attr = i.attrib\n",
    "                    string = i.text\n",
    "                    book = re.findall('(\\w+)',string)[-1]\n",
    "                    norm = attr['PUBKUERZEL']+' ' + attr['NORM']\n",
    "                    if norm not in norms:\n",
    "                        norms[norm] = {}\n",
    "                    art_abs = re.findall('(\\d+\\w+\\sAbs.\\s\\d+)',string)                     \n",
    "                    if art_abs==[]:\n",
    "                        if norm in norms[norm]:\n",
    "                            norms[norm][norm] += section_weights[section] \n",
    "                        else:\n",
    "                            norms[norm][norm] = section_weights[section] \n",
    "                    else:\n",
    "                        for s in art_abs:\n",
    "                            name = attr['PUBKUERZEL'] + ' '  + s\n",
    "                            if name in norms[norm]:\n",
    "                                norms[norm][name] += section_weights[section] \n",
    "                            else:\n",
    "                                norms[norm][name] = section_weights[section] \n",
    "                if i.tail is not None:\n",
    "                    string = i.tail\n",
    "                    try:\n",
    "                        ext = re.findall(pattern, string)\n",
    "                        processed=preprocess_extraction(ext)\n",
    "                        for e in processed:\n",
    "                            book = re.findall('(\\w+)',e)[-1]\n",
    "                            art = re.findall('(\\d+)',e)[0]\n",
    "                            norm = book + ' ' + art\n",
    "                            if norm not in norms:\n",
    "                                norms[norm] = {}\n",
    "                            art_abs = re.findall('(\\d+\\w+\\sAbs.\\s\\d+)',e)\n",
    "                            if art_abs==[]:\n",
    "                                if norm in norms[norm]:\n",
    "                                    norms[norm][norm] += section_weights[section]\n",
    "                                else:\n",
    "                                    norms[norm][norm] = section_weights[section]\n",
    "                            else:\n",
    "                                for s in art_abs:\n",
    "                                    name = book + ' '  + s\n",
    "                                    if name in norms[norm]:\n",
    "                                        norms[norm][name] += section_weights[section]\n",
    "                                    else:\n",
    "                                        norms[norm][name] = section_weights[section]                              \n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "    return norms\n",
    "\n",
    "\n",
    "def generate_normchain(norms, threshold = 2):\n",
    "# Select legal norms for norm chain output from the candidates\n",
    "# The details are described in the thesis\n",
    "    chain = []\n",
    "    \n",
    "    for (key, value) in norms.items():\n",
    "        if len(value) == 1:\n",
    "            for (key_2, value_2) in value.items():\n",
    "                if value_2 > threshold:\n",
    "                    key_2 = key_2.replace(u'\\xa0', u' ')\n",
    "                    chain.append(key_2)\n",
    "        else:\n",
    "            append_key = True\n",
    "            candidates = {}\n",
    "            for (key_2, value_2) in value.items():\n",
    "                if (value_2 > threshold) & (key_2 != key):\n",
    "                    key_2 = key_2.replace(u'\\xa0', u' ')\n",
    "                    candidates[key_2] = value_2\n",
    "                    append_key = False\n",
    "            if append_key:\n",
    "                key = key.replace(u'\\xa0', u' ')\n",
    "                chain.append(key)\n",
    "            else:\n",
    "                name = max(candidates, key=candidates.get)\n",
    "                name = name.replace(u'\\xa0', u' ')\n",
    "                chain.append(name)\n",
    "    return chain\n",
    "\n",
    "def extr2mat(arr):\n",
    "# This function extract the [info, value] pairs from the extracted norms. \n",
    "# E.g. norm string 'ZPO 139 Abs. 1' and 'ZPO 522' for a docuumentation is extracted as \n",
    "# a 3-D matrix [[[ZPO, Abs],[139, 1]],[['ZPO'],[522]]]\n",
    "    extraction = []\n",
    "    for n in arr:\n",
    "        s = re.findall('(\\D[a-zA-ZäüöÄÜÖß.]+\\d*[a-zA-ZäüöÄÜÖß.]*[-]*[a-zA-ZäüöÄÜÖß.]*[\\\\]*[a-zA-ZäüöÄÜÖß.]*)\\s',n)\n",
    "        s = [x.strip(' ') for x in s]\n",
    "        s = [x for x in s if len(x) > 1]       \n",
    "        remove = ['Art.', 'a.F.', 'i.V.m.', 'Anh.', 'zu', 'BW', 'i.d.F.','und', 'n.F.',\n",
    "                  'BEL', 'THA', 'BRA', 'FRA', 'CHE', 'Baugewerbe', 'Bund', 'Abschn.',\n",
    "                  'BT-K', 'NRW', 'Berlin', 'iVm.', 'NW', 'XII', 'II', 'Schl.-H.', 'MV',\n",
    "                  'Bln', 'RhPf', 'RP', '-H','Tageszeitungen',  'Flugsicherung', 'ATZ', 'DTAG',\n",
    "                  'DTTS', 'DRK', 'SH', 'UmBw', 'BKK', '(Zusatzabkommen',  'Einzelhandel','Sicherheit',\n",
    "                 'Bayern',  'dänischer', 'ATZ-TgRV', 'Bühne', 'BT-BBiG', 'Brandenburg', 'AWO','PV',\n",
    "                 '/Lackierer', 'Th','Art','nF','Baden-Württemberg','(jetzt', 'III','u.', 'analog','VI',\n",
    "                 'des','StVergAbG','JStG', 'AG','BeitrRLUmsG', 'd.', 'Rheinland-Pfalz','InfoV','Anhang','f.',\n",
    "                 'Hamburger', 'StSenkG','DDR', 'BR','IV','Abkommen', 'mehr', 'Bbg','a.2']\n",
    "        if len(s)>0:\n",
    "            s = [x for x in s if x not in remove]\n",
    "            if len(s)>1:\n",
    "                if s[0]==s[1]:\n",
    "                    s.pop(1)\n",
    "            d = re.findall('\\s(\\d+\\w*)',n)\n",
    "            if (len(s)>0) & (len(d)>0):\n",
    "                print(d)\n",
    "                extraction.append([s,d])\n",
    "    return extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the matching score\n",
    "# The scores are computed based on three different granularities:\n",
    "#     1. Law code abbreviation\n",
    "#     2. Law code abbreviation + Article number\n",
    "#     3. Law code abbreviation + Article number + Abs. paragraph number\n",
    "\n",
    "def compute_recall_score_AbbrArtPara(norm_mat, generate_mat):\n",
    "# Computed a matching score based on the number of TRUE and FALSE matching flags\n",
    "    flags =[]\n",
    "    for e in norm_mat:\n",
    "        print(e, 'is one legal norm in the label.')\n",
    "        if len(e[0])>len(e[1])+1:\n",
    "            # There are some norms have name consist of several words\n",
    "            # Skip calculating scores for these ones\n",
    "            continue\n",
    "        if (len(e[1])==1) & (len(e[0])>1):\n",
    "            # There are some norms in annotation with Absatz number but without artikle number\n",
    "            continue\n",
    "        book = e[0][0]\n",
    "        art = e[1][0]\n",
    "        book_flag = False\n",
    "        art_flag = False\n",
    "        abs_flag = None\n",
    "        for i in generate_mat:\n",
    "            if i[0][0]==book:\n",
    "                book_flag = True\n",
    "                if i[1][0]==art:\n",
    "                    art_flag = True\n",
    "                    for j in range(1,len(e[0])):\n",
    "                        if e[0][j]=='Abs.':\n",
    "                            absch = e[1][j]\n",
    "                            abs_flag = False\n",
    "                    for j in range(1,len(i[0])):\n",
    "                        if i[0][j]=='Abs.':\n",
    "                            absch_2 = i[1][j]\n",
    "                    try:\n",
    "                        if absch == absch_2:\n",
    "                            abs_flag = True\n",
    "                    except:\n",
    "                        pass\n",
    "        flags.append([book_flag, art_flag, abs_flag])\n",
    "    flags=np.array(flags)\n",
    "    if len(np.argwhere(flags==True))+len(np.argwhere(flags==False))>0:\n",
    "        score = len(np.argwhere(flags==True))/(len(np.argwhere(flags==True))+len(np.argwhere(flags==False)))\n",
    "    else:\n",
    "        score = -1\n",
    "    return score\n",
    "\n",
    "def compute_recall_score_AbbrArt(norm_mat, generate_mat):\n",
    "# Computed a matching score based on the number of TRUE and FALSE matching flags\n",
    "    flags =[]\n",
    "    for e in norm_mat:\n",
    "        print(e, 'is one legal norm in the label.')\n",
    "        if len(e[0])>len(e[1])+1:\n",
    "            # There are some norms have name consist of several words\n",
    "            # Skip calculating scores for these ones\n",
    "            continue\n",
    "        if (len(e[1])==1) & (len(e[0])>1):\n",
    "            # There are some norms in annotation with Absatz number but without artikle number\n",
    "            continue\n",
    "        book = e[0][0]\n",
    "        art = e[1][0]\n",
    "        book_flag = False\n",
    "        art_flag = False\n",
    "        for i in generate_mat:\n",
    "            if i[0][0]==book:\n",
    "                book_flag = True\n",
    "                if i[1][0]==art:\n",
    "                    art_flag = True\n",
    "        flags.append([book_flag, art_flag])\n",
    "    flags=np.array(flags)\n",
    "    if len(np.argwhere(flags==True))+len(np.argwhere(flags==False))>0:\n",
    "        score = len(np.argwhere(flags==True))/(len(np.argwhere(flags==True))+len(np.argwhere(flags==False)))\n",
    "    else:\n",
    "        score = -1\n",
    "    return score\n",
    "\n",
    "# Calculate the matching score\n",
    "def compute_recall_score_Abbr(norm_mat, generate_mat):\n",
    "# Computed a matching score based on the number of TRUE and FALSE matching flags\n",
    "    flags =[]\n",
    "    for e in norm_mat:\n",
    "        print(e, 'is one legal norm in the label.')\n",
    "        if len(e[0])>len(e[1])+1:\n",
    "            # There are some norms have name consist of several words\n",
    "            # Skip calculating scores for these ones\n",
    "            continue\n",
    "        if (len(e[1])==1) & (len(e[0])>1):\n",
    "            # There are some norms in annotation with Absatz number but without artikle number\n",
    "            continue\n",
    "        book = e[0][0]\n",
    "        art = e[1][0]\n",
    "        book_flag = False\n",
    "        for i in generate_mat:\n",
    "            if i[0][0]==book:\n",
    "                book_flag = True\n",
    "        flags.append([book_flag])\n",
    "    flags=np.array(flags)\n",
    "    if len(np.argwhere(flags==True))+len(np.argwhere(flags==False))>0:\n",
    "        score = len(np.argwhere(flags==True))/(len(np.argwhere(flags==True))+len(np.argwhere(flags==False)))\n",
    "    else:\n",
    "        score = -1\n",
    "    return score\n",
    "\n",
    "# Calculate the matching score\n",
    "def compute_precision_score_AbbrArtPara(norm_mat, generate_mat):\n",
    "# Computed a matching score based on the number of TRUE and FALSE matching flags\n",
    "    flags =[]\n",
    "    for e in generate_mat:\n",
    "        print(e, 'is one legal norm in the generated chain.')\n",
    "        if len(e[0])>len(e[1])+1:\n",
    "            # There are some norms have name consist of several words\n",
    "            # Skip calculating scores for these ones\n",
    "            continue\n",
    "        if (len(e[1])==1) & (len(e[0])>1):\n",
    "            # There are some norms in annotation with Absatz number but without artikle number\n",
    "            continue\n",
    "        book = e[0][0]\n",
    "        art = e[1][0]\n",
    "        book_flag = False\n",
    "        art_flag = False\n",
    "        abs_flag = None\n",
    "        for i in norm_mat:\n",
    "            if len(i[0])>len(i[1])+1:\n",
    "                continue\n",
    "            if (len(i[1])==1) & (len(i[0])>1):\n",
    "                continue\n",
    "            if i[0][0]==book:\n",
    "                book_flag = True\n",
    "                if i[1][0]==art:\n",
    "                    art_flag = True\n",
    "                    for j in range(1,len(e[0])):\n",
    "                        if e[0][j]=='Abs.':\n",
    "                            absch = e[1][j]\n",
    "                            abs_flag = False\n",
    "                    for j in range(1,len(i[0])):\n",
    "                        if i[0][j]=='Abs.':\n",
    "                            print(i)\n",
    "                            absch_2 = i[1][j]\n",
    "                    try:\n",
    "                        if absch == absch_2:\n",
    "                            abs_flag = True\n",
    "                    except:\n",
    "                        pass\n",
    "        flags.append([book_flag, art_flag, abs_flag])\n",
    "    flags=np.array(flags)\n",
    "    if len(np.argwhere(flags==True))+len(np.argwhere(flags==False))>0:\n",
    "        score = len(np.argwhere(flags==True))/(len(np.argwhere(flags==True))+len(np.argwhere(flags==False)))\n",
    "    else:\n",
    "        score = -1\n",
    "    return score\n",
    "\n",
    "# Calculate the matching score\n",
    "def compute_precision_score_AbbrArt(norm_mat, generate_mat):\n",
    "# Computed a matching score based on the number of TRUE and FALSE matching flags\n",
    "    flags =[]\n",
    "    for e in generate_mat:\n",
    "        print(e, 'is one legal norm in the label.')\n",
    "        if len(e[0])>len(e[1])+1:\n",
    "            # There are some norms have name consist of several words\n",
    "            # Skip calculating scores for these ones\n",
    "            continue\n",
    "        if (len(e[1])==1) & (len(e[0])>1):\n",
    "            # There are some norms in annotation with Absatz number but without artikle number\n",
    "            continue\n",
    "        book = e[0][0]\n",
    "        art = e[1][0]\n",
    "        book_flag = False\n",
    "        art_flag = False\n",
    "        for i in norm_mat:\n",
    "            if i[0][0]==book:\n",
    "                book_flag = True\n",
    "                if i[1][0]==art:\n",
    "                    art_flag = True\n",
    "        flags.append([book_flag, art_flag])\n",
    "    flags=np.array(flags)\n",
    "    if len(np.argwhere(flags==True))+len(np.argwhere(flags==False))>0:\n",
    "        score = len(np.argwhere(flags==True))/(len(np.argwhere(flags==True))+len(np.argwhere(flags==False)))\n",
    "    else:\n",
    "        score = -1\n",
    "    return score\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
